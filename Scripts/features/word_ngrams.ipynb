{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"labeled_data.csv\",encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_words(raw_tweet):\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_tweet).get_text() \n",
    "    # 2. Remove non-letters        \n",
    "    #letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = review_text.lower().split()   \n",
    "    #words = letters_only.lower().split()            \n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    stops = set(stopwords.words(\"english\")) \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]  \n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 10000 of 121054\n",
      "\n",
      "Tweet 20000 of 121054\n",
      "\n",
      "Tweet 30000 of 121054\n",
      "\n",
      "Tweet 40000 of 121054\n",
      "\n",
      "Tweet 50000 of 121054\n",
      "\n",
      "Tweet 60000 of 121054\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/dALZL6ZuOV\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/daznQZR8Te\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/NXgtqSlchG\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/ltoXYPKWww\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/bN7be6njVT\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/3hqI0L6cwU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/nO5U2nLuGc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/YnGATgiK5F\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/W1WmvCXAvm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/iQF3M9X1NK\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/Xvg4LrPWD5\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/vSObneH81v\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/3nr1XjZaW6\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Kiki\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/f2NxFZ8VTz\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 70000 of 121054\n",
      "\n",
      "Tweet 80000 of 121054\n",
      "\n",
      "Tweet 90000 of 121054\n",
      "\n",
      "Tweet 100000 of 121054\n",
      "\n",
      "Tweet 110000 of 121054\n",
      "\n",
      "Tweet 120000 of 121054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_tweets = data[\"tweet\"].size\n",
    "clean_train_tweets = []\n",
    "for i in range( 0, num_tweets ):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print (\"Tweet %d of %d\\n\" % ( i+1, num_tweets ))                                                                    \n",
    "    clean_train_tweets.append( tweet_to_words( data.iloc[i][\"tweet\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the count vectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer = \"word\",   \\\n",
    "                             ngram_range=(1, 3),  \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 300,  \\\n",
    "                             max_df = 0.85) \n",
    "train_data_features = vectorizer.fit_transform(clean_train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_features = train_data_features.toarray()\n",
    "X = pd.DataFrame(train_data_features)\n",
    "y = data['class'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=69, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   1.3s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   1.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   1.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   1.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.7s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('select', SelectFromModel(LogisticRegression(class_weight='balanced', penalty=\"l1\", C=0.01))),\n",
    "                 ('model', LogisticRegression(class_weight='balanced',penalty='l2'))])\n",
    "\n",
    "param_grid = [{}]\n",
    "grid_search = GridSearchCV(pipe, param_grid,cv=StratifiedKFold(n_splits=5, random_state=69).split(X_train, y_train), verbose=2)\n",
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.61      0.71      8186\n",
      "           1       0.95      0.77      0.85     14805\n",
      "           2       0.74      0.97      0.84     16957\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     39948\n",
      "   macro avg       0.85      0.78      0.80     39948\n",
      "weighted avg       0.84      0.82      0.82     39948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=  41.9s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   51.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=  44.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  40.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  40.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  39.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "        [('select', SelectFromModel(LogisticRegression(class_weight='balanced',\n",
    "                                                  penalty=\"l1\", C=0.01))),\n",
    "        ('model', RandomForestClassifier(n_estimators=300, random_state=0))])\n",
    "\n",
    "param_grid = [{}] \n",
    "grid_search = GridSearchCV(pipe, param_grid,cv=StratifiedKFold(n_splits=5, random_state=69).split(X_train, y_train), verbose=2)\n",
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.63      0.72      8186\n",
      "           1       0.93      0.80      0.86     14805\n",
      "           2       0.76      0.94      0.84     16957\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     39948\n",
      "   macro avg       0.84      0.79      0.81     39948\n",
      "weighted avg       0.84      0.83      0.82     39948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   1.1s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   0.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   1.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.1s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('select', SelectFromModel(LogisticRegression(class_weight='balanced', penalty=\"l1\", C=0.01))),\n",
    "                 ('model', LinearSVC(C=0.05,random_state=0))])\n",
    "\n",
    "param_grid = [{}] \n",
    "grid_search = GridSearchCV(pipe, param_grid,cv=StratifiedKFold(n_splits=5, random_state=69).split(X_train, y_train), verbose=2)\n",
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.58      0.71      8186\n",
      "           1       0.95      0.77      0.85     14805\n",
      "           2       0.74      0.98      0.84     16957\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     39948\n",
      "   macro avg       0.86      0.78      0.80     39948\n",
      "weighted avg       0.85      0.82      0.82     39948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   0.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   0.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.4s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('select', SelectFromModel(LogisticRegression(class_weight='balanced', penalty=\"l1\", C=0.01))),\n",
    "                 ('model', ExtraTreeClassifier())])\n",
    "\n",
    "param_grid = [{}] \n",
    "grid_search = GridSearchCV(pipe, param_grid,cv=StratifiedKFold(n_splits=5, random_state=69).split(X_train, y_train), verbose=2)\n",
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.71      8186\n",
      "           1       0.93      0.80      0.86     14805\n",
      "           2       0.76      0.93      0.84     16957\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     39948\n",
      "   macro avg       0.84      0.79      0.81     39948\n",
      "weighted avg       0.84      0.82      0.82     39948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   0.7s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   0.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.1s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('select', SelectFromModel(LogisticRegression(class_weight='balanced', penalty=\"l1\", C=0.01))),\n",
    "                 ('model', BernoulliNB())])\n",
    "\n",
    "param_grid = [{}] \n",
    "grid_search = GridSearchCV(pipe, param_grid,cv=StratifiedKFold(n_splits=5, random_state=69).split(X_train, y_train), verbose=2)\n",
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.60      0.71      8186\n",
      "           1       0.87      0.79      0.83     14805\n",
      "           2       0.75      0.93      0.83     16957\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     39948\n",
      "   macro avg       0.83      0.77      0.79     39948\n",
      "weighted avg       0.82      0.81      0.80     39948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
