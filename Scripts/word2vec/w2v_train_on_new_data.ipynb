{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-training word2vec models on various unlabeled datasets and using the new models as input features to classify labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled = pd.read_csv(\"toxic_train.csv\", encoding=\"latin-1\")                    # jigsaqw kaggle\n",
    "#unlabeled = pd.read_csv(\"unlabeled_data.csv\")\n",
    "\n",
    "#unlabeled1 = pd.read_csv(\"aggression_annotated_comments.tsv\")                     # Wikipedia \n",
    "#unlabeled2 = pd.read_csv(\"toxicity_annotated_comments.tsv\")                       # Wikipedia\n",
    "#unlabeled = unlabeled1.append(unlabeled2)\n",
    "\n",
    "#trainGB = pd.read_csv(\"GBcomments.csv\", encoding=\"latin-1\")                       # yt us comments\n",
    "#trainUS = pd.read_csv(\"UScomments.csv\", encoding=\"latin-1\")                       # yt uk comments\n",
    "#unlabeled = trainGB.append(trainUS)\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')                     # Load the punkt tokenizer\n",
    "\n",
    "\n",
    "def tweet_to_wordlist( tweet, remove_stopwords=False):\n",
    "    tweet_text = BeautifulSoup(tweet).get_text()                                  # Remove HTML\n",
    "    tweet_text = re.sub(\"[^a-zA-Z]\",\" \", tweet_text)                              # Remove non-letters\n",
    "    words = tweet_text.lower().split()                                            # Convert to lower case and split\n",
    "    if remove_stopwords:                                                          # Optionally remove stop words \n",
    "        words = [w for w in words if not w in stops]\n",
    "    return(words)                                                                 # Return a list of words\n",
    "\n",
    "def tweet_to_sentences(tweet, tokenizer, remove_stopwords=False):\n",
    "    raw_sentences = tokenizer.tokenize(tweet.strip())                             # Split the paragraph into sents.\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:                                            # Loop over each sentence\n",
    "        if len(raw_sentence) > 0:                                                 # If a sentence is empty, skip it\n",
    "            sentences.append(tweet_to_wordlist(raw_sentence, remove_stopwords))   # Call tweet_to_wordlist to get wordlist\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'............'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://www.youtube.com/watch?v=EfBwz_SiK8s\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.rollingstone.com/music/videos/arctic-monkeys-cover-lou-reeds-walk-on-the-wild-side-20131029\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.politiqueinternationale.com/revue/article.php?id_revue=12&id;=228&content;=synopsis.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'....'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://laughingsquid.com/ozzy-the-weasel-adorably-interrupts-his-humans-video-games-by-playing-with-his-thumb/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Category:Berlin_Film_Festival\n",
      "http://en.wikipedia.org/wiki/Category:Cannes_Film_Festival\n",
      "http://en.wikipedia.org/wiki/Category:Venice_Film_Festival\n",
      "etc.\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Chad_Kellogg&diff;=603899892&oldid;=603899206\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://cityroom.blogs.nytimes.com/2007/08/13/brooke-astor-is-dead-at-105/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.bbc.co.uk/worldservice/learningenglish/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://www.cia.gov/library/center-for-the-study-of-intelligence/csi-publications/csi-studies/studies/vol48no2/article10.html\n",
      "\n",
      "....yeah.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.plp.org/books/Stalin/node131.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.gametrailers.com/player.php?type=wmv&id;=12509\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://archive.indianexpress.com/news/childrens-writer-leelavati-bhagwat-passes-away-in-pune/1199704/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=nADFJlAggnY\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/Wikipedia:Dispute_resolution_noticeboard\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'/'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.lublin.eu/Liublino_unijos_paskelbimo_aktas-1-927-27-1216.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.abc.net.au/news/stories/2010/12/28/3102725.htm?site=sport&section;=more.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://e-history.kz/en/contents/view/309\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://www.youtube.com/watch?v=jG7vhMMXagQ\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.p2pfoundation.net/Transfinancial_Economics\n",
      "\n",
      "____________________________________________________________________\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.onlineworldofwrestling.com/columns/huber/06.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Notability.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://news.xinhuanet.com/english/2009-07/06/content_11658819.htm.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://gogameguru.com/ichiriki-ryo-17th-nongshim-cup/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://weinerwatch.blogspot.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://kvetcher.net/2009/03/2798/vandalism-on-ohr-somayachs-wikipedia-page/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Acting_(law)\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.findarticles.com/p/articles/mi_m1132/is_n10_v48/ai_19344901\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://uncyclopedia.org/wiki/Encyclopedia_Dramatica\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.microfiber-products-online.com/faqs.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://images.google.com/images?hl=en&q;=joseph%20cafasso&sa;=N&tab;=wi\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://denverfuckedme.com/FY/viewtopic.php?f=7&t;=180&p;=365#p365\n",
      "\n",
      "NOTICE!\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://uncyclopedia.org/wiki/User:Sir_james_paul\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www-142.ibm.com/software/sw-lotus/products/product4.nsf/wdocs/dominoexpressfaq2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.newswire.ca/en/releases/archive/February2008/27/c6618.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://neer-do-well-hall-of-infamey.blogspot.ca/\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.athletix.org/Statistics/wr100men.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=6PaHcZUHI00\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.google.com/search?hl=en&q;=%CE%92%CE%BB%CE%B1%CF%87%CE%BF%CE%BC%CE%BF%CE%B3%CE%BB%CE%B5%CE%BD%CE%AF%CF%84%CE%B5%CF%82.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.parkinsons-information-exchange-network-online.com/parkmail1.1/2005a/msg00545.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://news.google.com/newspapers?id=ExYOAAAAIBAJ&sjid;=AX0DAAAAIBAJ&pg;=7099,3612274&dq;=barry-goldwater&hl;=en\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:CALC#Routine_calculations\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/User:Mdupont/SFK\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Hindi\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.morningsun.net/article/20130728/NEWS/307289949/10011/LIFESTYLE\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.wvculture.org/HISTORY/journal_wvh/wvh40-4.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://maps.google.com/?ie=UTF8&ll;=42.779275,-118.907776&spn;=0.48281,0.883026&z;=10\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.indiaglitz.com/channels/telugu/article/12528.html\n",
      "http://www.radiokhushi.com/music/telugu_songs.cgi?lang=t&movie;=apuroopam&rtype;=actress&name;=Priyanka%20Chopra\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://groups.google.tm/group/humanities.classics/browse_thread/thread/8f54ed822f0cef93\n",
      "h?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.reddit.com/r/todayilearned/comments/2nk6bg/til_the_town_thompson_falls_montana_is_completely/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=User_talk:StillStanding-247&oldid;=516333723#The_morning_after.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.myspace.com/jakewaskett\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://barmedfootball.com\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Attribution\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/Talk:Tiger_I#Mobility_and_Reliability\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://asian-defence.blogspot.com/2011/02/chinese-j-10-fighter-with-conformal.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.unitedstatesmartialartshalloffame.com/index.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.popsci.com/technology/article/2013-01/wikipedia-getting-worse-it-gets-better\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Talk:Rime_movement\n",
      "http://en.wikipedia.org/w/index.php?title=Rime_movement&action;=history\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://neer-do-well-hall-of-infamey.blogspot.ca/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://twincities.bizjournals.com/twincities/stories/2001/12/17/daily29.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Weather_balloon\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.space.com/scienceastronomy/arsenic-bacteria-alien-life-101202.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.encognitive.com/files/Top%20Japanese%20Surgeon%20Uses%20Gerson%20Therapy,%20Publishes%20Research.pdf\n",
      "\n",
      "\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://fr.wikipedia.org/wiki/Fichier:Accor_logo.svg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=User:Sir_james_paul&diff;=prev&oldid;=96291535\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://spamtheweb.com/ul/upload/030609/9642_DavidZX.php\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Harassment#Wikihounding\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/Wikipedia:Identifying_reliable_sources\n",
      "\n",
      "Eight?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/Talk:British_heavy_tanks_of_World_War_I#Mark_V_series_use_in_Berlin_1945\n",
      "\n",
      "Nine?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://defenceforumindia.com/forum/indian-army/7479-ancient-indian-weapons-great-indian-culture-2.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Falsifiability.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.gpsinformation.org/dale/gpsfix.htm\n",
      "72.185.61.209\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.facebook.com/help/#!/profile.php?id=100002283868363&sk;=wall\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://syracuseuniversity.qualtrics.com/SE/?SID=SV_2bnPZz0HelBaY85\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/w/index.php?title=\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=User_talk%3AMcGrandWizard.&diff;=98300007&oldid;=98000615\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.nj.com/mercer/index.ssf/2013/10/steinert_high_school_michigan_state_university_work_out_deal_to_use_football_helmet_logo.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.wondercomments.com/i_love_you/i_love_you_comment_09.gif\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/User:Corinna.jpg/Para_Site\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Talk:Star_Wars#Why_don.27t_we_talk_about_Star_Wars.27_prodigious_impact_on_pop_culture_in_the_opening_paragraph.3F\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://news.bbc.co.uk/1/hi/uk/264609.stm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Talk:Aaron\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.world-action.co.uk/independent.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.imdb.com/title/tt2470102/.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.guineapigkids.com/transcript.htm\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'\\\\'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://sites.google.com/site/fusedcellgames/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.nzherald.co.nz/section/1501119/story.cfm?c_id=1501119&objectid;=10427103\n",
      "\n",
      "http://www.britneyspears.org/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.nytimes.com/2005/06/08/international/08prexy.html?pagewanted=print\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Articles_for_deletion/Jude_Calvert-Toulmin#Jude_Calvert-Toulmin\n",
      "\n",
      "Thankyou.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.heretical.org/British/bnpfun.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=R-Da9ghk-sk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'/.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/Wikipedia:Requests_for_mediation/It%27s_%22Nepal_Bhasa%22\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.injusticeinperugia.org/FBI6.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Charging_Bull\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.vegettoex.com/blog/2009/12/16/why-the-frieza-spelling-drives-me-nuts/\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=2008_South_Ossetia_war&diff;=231158071&oldid;=231158017\n",
      "\n",
      "Greetings,\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Wikipedia:Requests_for_page_protection&oldid;=137392411\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.cnn.com/2006/SHOWBIZ/TV/12/04/television.lilbush.reut/index.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://myspace.com/workingitouttours\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.royal-navy.mod.uk/linkedfiles/referencelibrary/ref_library_docs/20110603bridgecard03jun11.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.telegraph.co.uk/connected/main.jhtml?xml=/connected/2002/11/06/ecfwitch06.xml\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://cartoon-coloring.com/joseph-barbera/.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://209.157.64.201/focus/user-posts?id=230253\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.jstor.org/stable/10.1525/vs.2014.8.4.1?seq=1#page_scan_tab_contents\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.gpoaccess.gov/911/pdf/fullreport.pdf\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Biographies_of_living_persons/Noticeboard#Talk:Phyllis_Schlafly:\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Requests_for_comment/Dominick\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.thewho.info/SellOut.htm\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Administrators%27_noticeboard/Incidents#User:Barneca\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.bbc.co.uk/religion/religions/atheism/features/h_j_blackham/index.shtml.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.jethros.i12.com/fleets/fleet_listings/ryanair.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'... .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.google.com/search?hl=en&safe;=off&q;=%22thomas+cannon%22+homosexuality&btnG;=Search\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://www.google.co.kr/webhp?sourceid=chrome-instant&ion;=1&espv;=2&ie;=UTF-8#newwindow=1&q;=value%20net%20adam%20brandenburger\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.boldbeautifulfan.com/bnbnews.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia_talk:Dispute_resolution_noticeboard\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://cerebralpalsy.org/about-cerebral-palsy/history-and-origin-of-cerebral-palsy/.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.ncbi.nlm.nih.gov/pubmedhealth/PMH0001734/.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.opsharecraft.com/\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/User:CristinaMishka/Baildsa\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.myspace.com/dnegreanu\n",
      "\n",
      "http://profile.myspace.com/index.cfm?fuseaction=user.viewprofile&friendid;=63618592\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=User_talk:Dinoguy2&action;=edit&section;=49\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.redpeppercases.com/Galaxy-S3-Cases_c4.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.asda-entertainment.co.uk/cd/taylor-swift/speak-now-deluxe/10271059.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/User:RolandR\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=User_talk:Fire_Star&diff;=132003957&oldid;=132003851\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'D:'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.urbandictionary.com/define.php?term=BatteryIncluded%20and%20Apokryltaros&defid;=7940701\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Talk:David_Kelly_%28weapons_expert%29\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://sfgate.com/cgi-bin/article.cgi?f=/c/a/2005/11/10/BAGGCFLLCI1.DTL\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://news.bbc.co.uk/onthisday/hi/dates/stories/june/4/newsid_2496000/2496277.stm\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.angelfire.com/wrestling/cawthon777/92.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/PlayStation_4#Console\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/User:Notavulgarusername\n",
      "\n",
      "\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/w/index.php?title=Spiro_Koleka&diff;=675471550&oldid;=675452574\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.holocaust-history.org/questions/porsche.shtml\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.myspace.com/elenagheorghe\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://groups.google.com/group/comp.sources.games/msg/c95f01a4febd9fb1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.amazon.com/Family-Tree-Guns-N-Roses/dp/B003B8NUYQ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/Talk:Garbage_picking#Garbage_Picking_to_Dumpster_Diving_Move.2Frename_should_be_reverted.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://www.osac.gov/Reports/report.cfm?contentID=66949\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Nazi_talking_dogs&oldid;=431078201.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/DHARMA_Initiative_stations\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.donmurphy.net/board/showthread.php?p=905501#post905501\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia_talk:No_original_research/archive15#YouTube_art_as_primary_source\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.european-council.europa.eu/media/750848/web_bce_28-29juin_2012.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/David_Roati\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.state.gov/g/drl/rls/102406.htm#_Toc174854655\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://espn.go.com/blog/ncfnation/post/_/id/23051/pac-10-makes-announcement-on-colorado\n",
      "75.102.128.133\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.fcbarcelona.cat/web/english/futbol/temporada_08-09/plantilla/jugadors/etoo.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.webcitation.org/6CP5fWl1Q).\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Special%3ALinksearch&target;=*.genx10.com\n",
      "\n",
      "Thanks!\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Image:Serif-Sans-Comparison.svg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Talk_Page_Guidelines#User_talk_pages\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Image:Buyids.png\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://oppositelock.kinja.com/the-ford-mustang-shelby-gt500s-nurburgring-lap-time-7-1455203202\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/User_talk:Beetstra#Removal_of_link_from_a_personal_page.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=hQ093U-ndpQ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.enotes.com/psychoanalysis-encyclopedia/unpleasure\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Dialogue\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://english.farsnews.com/newstext.aspx?nn=13920505001101\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/University_of_Prishtina_Kosovo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/Wikipedia:Deletion_review/Log/2014_December_19\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/%C5%A0pegelj_Tapes\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www2.anyoneforpimms.com/winterpages/winter_history.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=User_talk%3A68.103.31.116&diff;=240055316&oldid;=239995248\n",
      "\n",
      "68.103.31.116\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.marketwired.com/press-release/Zaldivacom-Announces-Marketing-Partnership-With-KlearGearcom-707893.htm\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=m7AHblQ3_oM\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/User_talk:Magnus2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://catalog.loc.gov/cgi-bin/Pwebrecon.cgi?Search_Arg=Rapid+method+of+Neo&Search;_Code=GKEY%5E*&PID;=UiYWt5ukOI8jeCjL7yydwSi2ZEytV0v&SEQ;=20081215183629&CNT;=100&HIST;=1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://finance.yahoo.com/news/7-fascinating-nuggets-another-bewildering-150348488.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://profile.myspace.com/index.cfm?fuseaction=user.viewprofile&friendid;=336684\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.p2pfoundation.net/Transfinancial_Economics\n",
      "\n",
      "R.Searle\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Template_talk:Campaignbox_Kurdish%E2%80%93Turkish_conflict&action;=edit&section;=1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://unrule.info/files/wank.mpeg\n",
      "\n",
      "Woah!\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'.....'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=ODXoISgU-0M\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.tdsb.on.ca/wwwdocuments/parents/safe_schools/docs/Schools%20by%20Alpha.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://commons.wikimedia.org/wiki/File:Kit_body_rangers_historic1.png\n",
      "http://commons.wikimedia.org/wiki/File:Kit_left_arm_rangers_historic1.png\n",
      "http://commons.wikimedia.org/wiki/File:Kit_right_arm_rangers_historic1.png\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.blogtext.org/andy/article/5867.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/W88\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.twnside.org.sg/title/twr147e.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.mathworks.in/matlabcentral/fileexchange/46483-2048-game-solver\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.firstworldwar.com/bio/petain.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/GoAnimate\n",
      "\n",
      "112.209.86.65\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/EA_Sports_MMA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.pharmacy-noprescription.com\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://searchworks.stanford.edu/view/6961677\n",
      "\n",
      "7.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:ANI\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Mutilation\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://de.youtube.com/watch?v=SA9gXqVDkFQ\n",
      "http://de.youtube.com/watch?v=fgVEtaUx070\n",
      "http://de.youtube.com/watch?v=Ijh2Fqd1ZPY\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=kdLgUPgq8-g\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3202504/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.google.com/search?hl=en&q;=Nokia+cell+phone+explode\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://upload.wikimedia.org/wikipedia/commons/b/be/Cabbit.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://articles.businessinsider.com/2009-11-23/tech/30012937_1_new-editors-jimmy-wales-wikipedia\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.myDBA4.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/w/index.php?title=Nasal_cycle&diff;=481892150&oldid;=481587764].\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://perezhilton.com/2008-05-18-its-official-married-and-baby-on-the-way#more-20617\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/User:Bahamut0013/bio\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Special:Contributions&target;=207.165.194.195\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.google.com/hostednews/afp/article/ALeqM5goy8ODeG_SrxWu97fFyiHOMvWVag?docId=CNG.f8680b7c6577581edbb44fca91d20f82.5e1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Freedom_of_speech\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.shilohshepherds.info/otherBreeders.htm.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.guardian.co.uk/world/2013/apr/11/uruguay-legalises-same-sex-marriage\n",
      "http://www.bbc.co.uk/news/world-22184232\n",
      "\n",
      "~~eejaffer~~\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://findarticles.com/p/articles/mi_m2320/is_n4_v59/ai_18445600.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.pesquisapsi.com/books/advances4/7_Methodological_Criticisms.html.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.pesquisapsi.com/books/advances5/6_Criticism_in_Experimental.html.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://findarticles.com/p/articles/mi_m2320/is_n2_v60/ai_18960809.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.amazon.com/gp/product/0669397180/103-8410117-2081445?v=glance&n;=283155).\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/WA_2000\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://rexcurry.net/book1a1contents-pledge.html\n",
      "\n",
      "3.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Administrators%27_noticeboard/Incidents\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.pritzkermilitarylibrary.org/events/2007-03-22-leoThorsness.jsp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://www.youtube.com/watch?v=2laUr8W7ag0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.encyclopediadramatica.com/index.php/Fuck.org.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/w/index.php?title=UFC_191&action;=history\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.wwe.com/shows/raw/special/allspecialguesthosts/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:The_Great_Wikipedia_Dramaout/3rd#Participating_Wikipedians\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.mediabistro.com/tvnewser/ratings/the_scoreboard_friday_june_12_118993.asp\n",
      "\n",
      "Wow!\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.madrid.org/cs/Satellite?apartado=4&cid;=1139836016398&idioma;=_es&pagename;=PortalConsumo%2FPage%2FPTCO_DetalleSectoresPageTemplate&sector;=1139836019941\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/w/index.php?title=Spyromilios&oldid;=675469455&diff;=prev\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://abcnews.go.com/Politics/Story?id=2822061&page;=1\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Heriot_Vale_A.F.C.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Articles_for_deletion/Stimulsoft_Reports\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://weblogs.variety.com/thompsononhollywood/american_gangster/index.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=User:Precious_Roy&action;=history\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.skepticfiles.org/can/can-bbs.htm\n",
      ".\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/profile?user=NaturalNeil\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://royalsociety.org/people/fellowship/2015/clifford-cocks/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/User:Leprof_7272\n",
      "\n",
      "https://en.wikipedia.org/wiki/Talk:Western_culture#Source_review_begun\n",
      "\n",
      "Thanks\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://books.google.com/books?id=num2I4NFGqIC&pg;=PA36&lpg;=PA36&dq;=kushwaha+as+agricultural+caste&source;=bl&ots;=RbDJiP1vn-&sig;=0q5PXMIR2U-OdCfKoETdjdD8EGo&hl;=en&sa;=X&ei;=ha7IUfKZBI-o9gTApIDQAQ&ved;=0CC8Q6AEwATgo#v=onepage&q;=kushwaha&f;=false\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://time.com/3956492/bernie-sanders-new-hampshire-ballot/.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://web.archive.org/web/20020421154909/http://www.4dw.net/royalark/Turkey/turkey9.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://wikipediawehaveaproblem.com/evidence-of-cyberbullying-wp-editors-and-admins/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.planetlaughs.com\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://wikimediafoundation.org/wiki/Terms_of_Use#4._Refraining_from_Certain_Activities\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.knowhiphop.com/the-game-puts-rap-down-and-might-be-a-fourth-album/article/500.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.macobserver.com/tmo/article/apple_responds_to_psystar_appeal_in_mac_clone_battle/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:ELYES\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.staythirstymedia.com/news/43/335-greg-ginn.html.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://geomaps.wr.usgs.gov/parks/province/basinrange.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.newadvent.org/cathen/13121a.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Cypress_Park,_Los_Angeles,_California&diff;=prev&oldid;=318871908\n",
      "\n",
      "Hi!\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.muppetcentral.com/forum/threads/may-16-2011-saying-goodbye-to-jim-henson-21-years-later.47663/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://web.archive.org/web/20030629161605/http://users.telerama.com/~joseph/simple.html.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/User:AbbeyMaynard/sandbox\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.colorado.edu/journals/cye/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:What_Wikipedia_is_not#Wikipedia_is_not_an_indiscriminate_collection_of_information\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://wikiconferenceusa.org/wiki/2015/Main_Page\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Censorship_in_the_People%27s_Republic_of_China\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.rottentomatoes.com/guides/summer-movie-scorecard-2013/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.bbc.com/news/world-asia-india-26222496\n",
      "\n",
      "http://www.ibtimes.com/high-profile-indian-journalist-charged-rape-tarun-tejpal-victim-conspiracy-1555993\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=Q7pLw_ORWNM.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.kosovasoftwarefreedom.org/index.php/sfk09/call-for-papers.html\n",
      "\n",
      "Thanks,\n",
      "\n",
      "mike\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://commons.wikimedia.org/wiki/User_talk:Hanibal911#Re:Syria_map\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.presaletoday.com/in-flames-and-killswitch-engage-with-guests-protest-the-hero-and-between-the-buried-and-me-presale-passwords\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://s3.amazonaws.com/kony2012/kony_5.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.encyclopediadramatica.com/Jaranda\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.wetpaint.com/glee/articles/five-reasons-why-pitch-perfect-is-basically-a-glee-rip-off\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.ccgpp.org/view.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.zundelsite.org/zundel_persecuted/aug10_rally.html\n",
      "\n",
      "Well,...?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9F%E0%B8%A5%E0%B9%8C:Yingrak.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.jpost.com/International/Article.aspx?id=185741\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.shilohshepherds.info/shilohShepherdsWhatRThey.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/ErdinÃ§_Tekir\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://forums.steampowered.com/forums/showthread.php?t=2327958\n",
      "\n",
      "http://forums.steampowered.com/forums/showthread.php?t=2266373\n",
      "\n",
      "68.103.67.63\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.encognitive.com/files/Top%20Japanese%20Surgeon%20Uses%20Gerson%20Therapy,%20Publishes%20Research.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Charlemagne&curid;=5314&diff;=67029761&oldid;=67020446\n",
      "Anyway.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=ySAzyi8ivqA&feature;=related\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=User_talk:216.240.7.14&diff;=234168217&oldid;=234154700\n",
      "\n",
      "\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://progress.psu.edu/assets/content/REPORT_FINAL_071212.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/United_Cracking_Force\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.google.com/search?hl=en&client;=firefox-a&tbo;=p&rls;=org.mozilla%3Aen-US%3Aofficial&tbs;=nws%3A1&q;=irs+16%2C500&aq;=f&aqi;=&aql;=&oq;=&gs;_rfai=\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Mediation_Cabal/Cases/2010-07-25/Six-Day_War\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.wrestlingclassics.com/wawli/Nos.281-289.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://ultimate-guitar.com/news/general_music_news/red_hot_chili_peppers_accused_in_plagiarism.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.ifyouonlynews.com/science/rupert-murdoch-turns-national-geographic-into-fox-news-lays-off-fact-checkers/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://en.wikipedia.org/wiki/James_W._Pennebaker\n",
      "https://en.wikipedia.org/wiki/Self-disclosure\n",
      "https://en.wikipedia.org/wiki/Subject-expectancy_effect\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'........'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://nl.wikipedia.org/wiki/Eduard_Pellens\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.pinknews.co.uk/2009/11/27/australian-gay-marriage-could-lead-to-incest-and-polygamy-religious-figures-say/\n",
      "http://www.lifesitenews.com/ldn/2009/jan/09012207.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.ritasice.com/cool-treats/menu/italian-ice.aspx\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Star_wars\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Talk:Hephthalite\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.wetpaint.com/glee/video/brotherly-love-football-star-mychal-rivera-praises-big-sister-naya\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://encheveg.blog.bg/technology/2015/03/25/.1348923\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.waytooloud.com/2009/03/25/vanna-a-new-hope-2/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://antwrp.gsfc.nasa.gov/apod/ap020709.html?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://crypto.stackexchange.com/a/5837).\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.bbc.co.uk/news/world-africa-27006876\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:273: UserWarning: \"b'.. .'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Talk:Occupy_Marines#New_Subterfuge_re_Primary_Sources.3F\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://lenta.ru/news/2013/01/21/isk/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Strasbourg-Ortenau&diff;=244323620&oldid;=243185554.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.forteantimes.com/articles/194_evp1.shtml-\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.nypost.com/seven/07172007/gossip/pagesix/pagesix.htm\n",
      "\n",
      "68.183.100.3\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.corpus.pa.net/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.guardian.co.uk/environment/2007/aug/31/climatechange.food\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.gregpalast.com/detail.cfm?artid=27&row;=2\n",
      "http://elandslide.org/display.cfm?id=181\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://runescape.wikia.com/wiki/Main_Page\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.amazon.com/We-Sing-Dance-Steal-Things/dp/B0013FNC38/ref=pd_bbs_sr_1?ie=UTF8&s;=music&qid;=1208809990&sr;=8-1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Don%27t_restore_removed_comments\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Instituto_Balseiro&oldid;=40766799\n",
      "\n",
      "etc.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://moe.imouto.org/post/show/22615/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia_talk:Requests_for_mediation/Monty_Hall_problem\n",
      "\n",
      "Thanks.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://crypto.csail.mit.edu/classes/6.876/papers/gmr-ZK.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://umn.qualtrics.com/SE/?SID=SV_bvm2A1lvzYfJN9H\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.addcontent.net/.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.haaretz.com/news/diplomacy-defense/2-279-calories-per-person-how-israel-made-sure-gaza-didn-t-starve.premium-1.470419\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.nytimes.com/2010/09/05/arts/television/05schimmel.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://propagandapress.org/2007/02/21/fuck-bubba-by-saab-lofton/\n",
      "http://propagandapress.org/2007/02/26/man-fuck-florida-talking-shit-about-cuba-saab-lofton/\n",
      "http://activistsinlasvegas.blogspot.com/2006/12/rules-for-whites-by-saab-lofton.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Talk:Glock_pistol\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.wtorrent.com/btinfo.aspx?bt_id=401453\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.history.com/shows.do?action=detail&episodeId;=389122\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.qantas.com.au/infodetail/about/FactFiles.pdf\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/The_Secret_%28book%29#Criticism_and_parody\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.tomflocco.com/fs/911WidowQuestions.htm\n",
      "http://www.truthout.org/docs_01/01.05B.Klausutis.1.htm\n",
      "http://www.americanpolitics.com/20030721Baker.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Prototype_filter&action;=historysubmit&diff;=437083245&oldid;=389531293\n",
      "77.229.126.143\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.rts.edu/quarterly/winter01/parsons.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.google.com/search?hl=en&q;=%22B%C3%A1nh+T%E1%BA%BFt%22&btnG;=Google+Search\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://fr.wikipedia.org/wiki/Anna_Sprengel\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=GUID_Partition_Table&action;=historysubmit&diff;=397786496&oldid;=397444859\n",
      "\n",
      "173.26.162.40\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/UNOVER\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.defence.lk/news/20110801_Conf.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.historyplace.com/lincoln/dred.htm'\"\"\n",
      "\n",
      "2.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://wikipediareview.com/blog/20081106/181/#more-181\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Serbs_of_Croatia&diff;=198582584&oldid;=198570352\n",
      "\n",
      "2.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://books.google.com/books?id=SP8WAQAAMAAJ&q;=Trail+of+blood+and+tears+%2B+native+american&dq;=Trail+of+blood+and+tears+%2B+native+american&hl;=en&ei;=Dq6CTv3GHtK3tgepoMDeBw&sa;=X&oi;=book_result&ct;=result&resnum;=8&sqi;=2&ved;=0CFUQ6AEwBw\n",
      "\n",
      "2.)\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.thecheesecakefactory.com/Locations/locations#\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://www.wired.de/collection/latest/tschechische-architekten-bauen-ein-riesiges-holzgestell-mit-rutsche\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://ria.ru/politics/20100419/224129198.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.bibliotecapleyades.net/sociopolitica/esp_sociopol_lucytrust04.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:Please_do_not_bite_the_newcomers.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.orport.ang.af.mil/units.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/User_talk:24.43.231.210\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.vatican.va/holy_father/benedict_xvi/index.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.fordham.edu/halsall/mod/1950-gromyko-korea.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/w/index.php?title=Battle_of_Budapest&oldid;=48401057\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.theregister.co.uk/2007/12/04/wikipedia_secret_mailing/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=Vc9WJ9U2uHo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Oregon_Route_205\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://brainimmune.com/andor-szentivanyi-and-the-beta-adrenergic-theory-of-allergy-and-asthma/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://static.panoramio.com/photos/original/4180685.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://rexcurry.net/pledgesalute.html\n",
      "\n",
      "2.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "sentences = []                                                                    # Initialize an empty sentence list\n",
    "\n",
    "print (\"Parsing sentences from training set\")\n",
    "for tweet in unlabeled[\"comment_text\"]:\n",
    "    sentences += tweet_to_sentences(tweet, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2019-04-05 13:09:43,288 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2019-04-05 13:09:43,304 : INFO : collecting all words and their counts\n",
      "2019-04-05 13:09:43,304 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-04-05 13:09:43,382 : INFO : PROGRESS: at sentence #10000, processed 156306 words, keeping 14649 word types\n",
      "2019-04-05 13:09:43,460 : INFO : PROGRESS: at sentence #20000, processed 315608 words, keeping 21801 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-05 13:09:43,538 : INFO : PROGRESS: at sentence #30000, processed 463024 words, keeping 27239 word types\n",
      "2019-04-05 13:09:43,616 : INFO : PROGRESS: at sentence #40000, processed 616031 words, keeping 32105 word types\n",
      "2019-04-05 13:09:43,694 : INFO : PROGRESS: at sentence #50000, processed 769480 words, keeping 36426 word types\n",
      "2019-04-05 13:09:43,772 : INFO : PROGRESS: at sentence #60000, processed 925504 words, keeping 40436 word types\n",
      "2019-04-05 13:09:43,866 : INFO : PROGRESS: at sentence #70000, processed 1086615 words, keeping 44484 word types\n",
      "2019-04-05 13:09:43,944 : INFO : PROGRESS: at sentence #80000, processed 1235894 words, keeping 47871 word types\n",
      "2019-04-05 13:09:44,037 : INFO : PROGRESS: at sentence #90000, processed 1385716 words, keeping 51166 word types\n",
      "2019-04-05 13:09:44,146 : INFO : PROGRESS: at sentence #100000, processed 1531970 words, keeping 54109 word types\n",
      "2019-04-05 13:09:44,224 : INFO : PROGRESS: at sentence #110000, processed 1686312 words, keeping 57504 word types\n",
      "2019-04-05 13:09:44,334 : INFO : PROGRESS: at sentence #120000, processed 1841822 words, keeping 60480 word types\n",
      "2019-04-05 13:09:44,412 : INFO : PROGRESS: at sentence #130000, processed 1995805 words, keeping 63316 word types\n",
      "2019-04-05 13:09:44,536 : INFO : PROGRESS: at sentence #140000, processed 2153821 words, keeping 66058 word types\n",
      "2019-04-05 13:09:44,630 : INFO : PROGRESS: at sentence #150000, processed 2316630 words, keeping 68862 word types\n",
      "2019-04-05 13:09:44,708 : INFO : PROGRESS: at sentence #160000, processed 2474868 words, keeping 71604 word types\n",
      "2019-04-05 13:09:44,786 : INFO : PROGRESS: at sentence #170000, processed 2630505 words, keeping 74134 word types\n",
      "2019-04-05 13:09:44,864 : INFO : PROGRESS: at sentence #180000, processed 2786305 words, keeping 76503 word types\n",
      "2019-04-05 13:09:44,942 : INFO : PROGRESS: at sentence #190000, processed 2942981 words, keeping 79044 word types\n",
      "2019-04-05 13:09:45,036 : INFO : PROGRESS: at sentence #200000, processed 3097279 words, keeping 81519 word types\n",
      "2019-04-05 13:09:45,145 : INFO : PROGRESS: at sentence #210000, processed 3241377 words, keeping 83670 word types\n",
      "2019-04-05 13:09:45,238 : INFO : PROGRESS: at sentence #220000, processed 3397702 words, keeping 85991 word types\n",
      "2019-04-05 13:09:45,332 : INFO : PROGRESS: at sentence #230000, processed 3551311 words, keeping 88098 word types\n",
      "2019-04-05 13:09:45,441 : INFO : PROGRESS: at sentence #240000, processed 3698357 words, keeping 90189 word types\n",
      "2019-04-05 13:09:45,504 : INFO : PROGRESS: at sentence #250000, processed 3847287 words, keeping 92451 word types\n",
      "2019-04-05 13:09:45,628 : INFO : PROGRESS: at sentence #260000, processed 4001804 words, keeping 94408 word types\n",
      "2019-04-05 13:09:45,722 : INFO : PROGRESS: at sentence #270000, processed 4160559 words, keeping 96557 word types\n",
      "2019-04-05 13:09:45,816 : INFO : PROGRESS: at sentence #280000, processed 4309552 words, keeping 98583 word types\n",
      "2019-04-05 13:09:45,894 : INFO : PROGRESS: at sentence #290000, processed 4461830 words, keeping 100611 word types\n",
      "2019-04-05 13:09:46,018 : INFO : PROGRESS: at sentence #300000, processed 4614615 words, keeping 102720 word types\n",
      "2019-04-05 13:09:46,128 : INFO : PROGRESS: at sentence #310000, processed 4768195 words, keeping 104789 word types\n",
      "2019-04-05 13:09:46,268 : INFO : PROGRESS: at sentence #320000, processed 4926164 words, keeping 106757 word types\n",
      "2019-04-05 13:09:46,377 : INFO : PROGRESS: at sentence #330000, processed 5082830 words, keeping 108673 word types\n",
      "2019-04-05 13:09:46,502 : INFO : PROGRESS: at sentence #340000, processed 5241971 words, keeping 110566 word types\n",
      "2019-04-05 13:09:46,596 : INFO : PROGRESS: at sentence #350000, processed 5394089 words, keeping 112420 word types\n",
      "2019-04-05 13:09:46,736 : INFO : PROGRESS: at sentence #360000, processed 5547834 words, keeping 114376 word types\n",
      "2019-04-05 13:09:46,861 : INFO : PROGRESS: at sentence #370000, processed 5707927 words, keeping 116195 word types\n",
      "2019-04-05 13:09:46,954 : INFO : PROGRESS: at sentence #380000, processed 5866635 words, keeping 118084 word types\n",
      "2019-04-05 13:09:47,017 : INFO : PROGRESS: at sentence #390000, processed 6020613 words, keeping 119841 word types\n",
      "2019-04-05 13:09:47,126 : INFO : PROGRESS: at sentence #400000, processed 6176702 words, keeping 121500 word types\n",
      "2019-04-05 13:09:47,220 : INFO : PROGRESS: at sentence #410000, processed 6334282 words, keeping 123247 word types\n",
      "2019-04-05 13:09:47,282 : INFO : PROGRESS: at sentence #420000, processed 6484393 words, keeping 124904 word types\n",
      "2019-04-05 13:09:47,360 : INFO : PROGRESS: at sentence #430000, processed 6640303 words, keeping 126617 word types\n",
      "2019-04-05 13:09:47,469 : INFO : PROGRESS: at sentence #440000, processed 6796253 words, keeping 128306 word types\n",
      "2019-04-05 13:09:47,563 : INFO : PROGRESS: at sentence #450000, processed 6956478 words, keeping 130027 word types\n",
      "2019-04-05 13:09:47,656 : INFO : PROGRESS: at sentence #460000, processed 7112521 words, keeping 131743 word types\n",
      "2019-04-05 13:09:47,750 : INFO : PROGRESS: at sentence #470000, processed 7272101 words, keeping 133321 word types\n",
      "2019-04-05 13:09:47,812 : INFO : PROGRESS: at sentence #480000, processed 7424410 words, keeping 134888 word types\n",
      "2019-04-05 13:09:47,922 : INFO : PROGRESS: at sentence #490000, processed 7583761 words, keeping 136639 word types\n",
      "2019-04-05 13:09:48,031 : INFO : PROGRESS: at sentence #500000, processed 7739752 words, keeping 138455 word types\n",
      "2019-04-05 13:09:48,109 : INFO : PROGRESS: at sentence #510000, processed 7892361 words, keeping 140101 word types\n",
      "2019-04-05 13:09:48,202 : INFO : PROGRESS: at sentence #520000, processed 8048272 words, keeping 141665 word types\n",
      "2019-04-05 13:09:48,343 : INFO : PROGRESS: at sentence #530000, processed 8202543 words, keeping 143231 word types\n",
      "2019-04-05 13:09:48,483 : INFO : PROGRESS: at sentence #540000, processed 8357461 words, keeping 144762 word types\n",
      "2019-04-05 13:09:48,577 : INFO : PROGRESS: at sentence #550000, processed 8511805 words, keeping 146265 word types\n",
      "2019-04-05 13:09:48,655 : INFO : PROGRESS: at sentence #560000, processed 8674472 words, keeping 147857 word types\n",
      "2019-04-05 13:09:48,748 : INFO : PROGRESS: at sentence #570000, processed 8833772 words, keeping 149454 word types\n",
      "2019-04-05 13:09:48,842 : INFO : PROGRESS: at sentence #580000, processed 8990705 words, keeping 150876 word types\n",
      "2019-04-05 13:09:48,951 : INFO : PROGRESS: at sentence #590000, processed 9140489 words, keeping 152313 word types\n",
      "2019-04-05 13:09:49,060 : INFO : PROGRESS: at sentence #600000, processed 9300508 words, keeping 153925 word types\n",
      "2019-04-05 13:09:49,138 : INFO : PROGRESS: at sentence #610000, processed 9458759 words, keeping 155535 word types\n",
      "2019-04-05 13:09:49,216 : INFO : PROGRESS: at sentence #620000, processed 9617259 words, keeping 157222 word types\n",
      "2019-04-05 13:09:49,294 : INFO : PROGRESS: at sentence #630000, processed 9775228 words, keeping 158835 word types\n",
      "2019-04-05 13:09:49,388 : INFO : PROGRESS: at sentence #640000, processed 9926664 words, keeping 160139 word types\n",
      "2019-04-05 13:09:49,466 : INFO : PROGRESS: at sentence #650000, processed 10081985 words, keeping 161619 word types\n",
      "2019-04-05 13:09:49,544 : INFO : PROGRESS: at sentence #660000, processed 10243418 words, keeping 163138 word types\n",
      "2019-04-05 13:09:49,638 : INFO : PROGRESS: at sentence #670000, processed 10402040 words, keeping 164655 word types\n",
      "2019-04-05 13:09:49,716 : INFO : PROGRESS: at sentence #680000, processed 10556250 words, keeping 165987 word types\n",
      "2019-04-05 13:09:49,809 : INFO : PROGRESS: at sentence #690000, processed 10714532 words, keeping 167413 word types\n",
      "2019-04-05 13:09:49,887 : INFO : PROGRESS: at sentence #700000, processed 10865379 words, keeping 168760 word types\n",
      "2019-04-05 13:09:49,887 : INFO : collected 168807 word types from a corpus of 10872154 raw words and 700392 sentences\n",
      "2019-04-05 13:09:49,903 : INFO : Loading a fresh vocabulary\n",
      "2019-04-05 13:09:50,074 : INFO : min_count=40 retains 10838 unique words (6% of original 168807, drops 157969)\n",
      "2019-04-05 13:09:50,090 : INFO : min_count=40 leaves 10282083 word corpus (94% of original 10872154, drops 590071)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-05 13:09:50,215 : INFO : deleting the raw counts dictionary of 168807 items\n",
      "2019-04-05 13:09:50,215 : INFO : sample=0.001 downsamples 54 most-common words\n",
      "2019-04-05 13:09:50,230 : INFO : downsampling leaves estimated 7613068 word corpus (74.0% of prior 10282083)\n",
      "2019-04-05 13:09:50,308 : INFO : estimated required memory for 10838 words and 300 dimensions: 31430200 bytes\n",
      "2019-04-05 13:09:50,308 : INFO : resetting layer weights\n",
      "2019-04-05 13:09:50,636 : INFO : training model with 4 workers on 10838 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-04-05 13:09:51,697 : INFO : EPOCH 1 - PROGRESS: at 3.62% examples, 264482 words/s, in_qsize 6, out_qsize 2\n",
      "2019-04-05 13:09:52,726 : INFO : EPOCH 1 - PROGRESS: at 7.83% examples, 290240 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:09:53,725 : INFO : EPOCH 1 - PROGRESS: at 12.59% examples, 311163 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:09:54,754 : INFO : EPOCH 1 - PROGRESS: at 17.26% examples, 318222 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:09:55,815 : INFO : EPOCH 1 - PROGRESS: at 20.95% examples, 308356 words/s, in_qsize 7, out_qsize 3\n",
      "2019-04-05 13:09:56,876 : INFO : EPOCH 1 - PROGRESS: at 25.42% examples, 311476 words/s, in_qsize 8, out_qsize 2\n",
      "2019-04-05 13:09:57,874 : INFO : EPOCH 1 - PROGRESS: at 29.84% examples, 313828 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:09:58,904 : INFO : EPOCH 1 - PROGRESS: at 33.49% examples, 308694 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:09:59,902 : INFO : EPOCH 1 - PROGRESS: at 37.21% examples, 304769 words/s, in_qsize 6, out_qsize 0\n",
      "2019-04-05 13:10:00,901 : INFO : EPOCH 1 - PROGRESS: at 42.07% examples, 310358 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:02,071 : INFO : EPOCH 1 - PROGRESS: at 45.73% examples, 302910 words/s, in_qsize 7, out_qsize 4\n",
      "2019-04-05 13:10:03,085 : INFO : EPOCH 1 - PROGRESS: at 49.55% examples, 302010 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-05 13:10:04,146 : INFO : EPOCH 1 - PROGRESS: at 53.02% examples, 297733 words/s, in_qsize 7, out_qsize 1\n",
      "2019-04-05 13:10:05,160 : INFO : EPOCH 1 - PROGRESS: at 58.09% examples, 303939 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:06,174 : INFO : EPOCH 1 - PROGRESS: at 63.55% examples, 310820 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:07,266 : INFO : EPOCH 1 - PROGRESS: at 68.45% examples, 313052 words/s, in_qsize 7, out_qsize 3\n",
      "2019-04-05 13:10:08,280 : INFO : EPOCH 1 - PROGRESS: at 72.26% examples, 311799 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:09,309 : INFO : EPOCH 1 - PROGRESS: at 77.07% examples, 314022 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-05 13:10:10,386 : INFO : EPOCH 1 - PROGRESS: at 82.00% examples, 316426 words/s, in_qsize 7, out_qsize 2\n",
      "2019-04-05 13:10:11,400 : INFO : EPOCH 1 - PROGRESS: at 86.66% examples, 318030 words/s, in_qsize 7, out_qsize 1\n",
      "2019-04-05 13:10:12,398 : INFO : EPOCH 1 - PROGRESS: at 91.86% examples, 321703 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:13,412 : INFO : EPOCH 1 - PROGRESS: at 96.46% examples, 323017 words/s, in_qsize 6, out_qsize 0\n",
      "2019-04-05 13:10:14,036 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-05 13:10:14,052 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-05 13:10:14,067 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-05 13:10:14,067 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-05 13:10:14,083 : INFO : EPOCH - 1 : training on 10872154 raw words (7612912 effective words) took 23.4s, 325330 effective words/s\n",
      "2019-04-05 13:10:15,144 : INFO : EPOCH 2 - PROGRESS: at 3.99% examples, 285634 words/s, in_qsize 3, out_qsize 4\n",
      "2019-04-05 13:10:16,189 : INFO : EPOCH 2 - PROGRESS: at 9.40% examples, 340711 words/s, in_qsize 5, out_qsize 2\n",
      "2019-04-05 13:10:17,187 : INFO : EPOCH 2 - PROGRESS: at 14.89% examples, 361386 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:18,201 : INFO : EPOCH 2 - PROGRESS: at 18.48% examples, 339167 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:19,215 : INFO : EPOCH 2 - PROGRESS: at 22.23% examples, 328952 words/s, in_qsize 5, out_qsize 2\n",
      "2019-04-05 13:10:20,229 : INFO : EPOCH 2 - PROGRESS: at 26.70% examples, 330546 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:21,243 : INFO : EPOCH 2 - PROGRESS: at 32.21% examples, 341397 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:22,288 : INFO : EPOCH 2 - PROGRESS: at 37.22% examples, 343533 words/s, in_qsize 5, out_qsize 2\n",
      "2019-04-05 13:10:23,396 : INFO : EPOCH 2 - PROGRESS: at 41.40% examples, 336322 words/s, in_qsize 8, out_qsize 6\n",
      "2019-04-05 13:10:24,426 : INFO : EPOCH 2 - PROGRESS: at 46.74% examples, 341986 words/s, in_qsize 4, out_qsize 3\n",
      "2019-04-05 13:10:25,424 : INFO : EPOCH 2 - PROGRESS: at 51.85% examples, 346238 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:26,469 : INFO : EPOCH 2 - PROGRESS: at 56.66% examples, 347127 words/s, in_qsize 5, out_qsize 3\n",
      "2019-04-05 13:10:27,483 : INFO : EPOCH 2 - PROGRESS: at 61.71% examples, 349385 words/s, in_qsize 4, out_qsize 3\n",
      "2019-04-05 13:10:28,575 : INFO : EPOCH 2 - PROGRESS: at 66.07% examples, 346336 words/s, in_qsize 2, out_qsize 5\n",
      "2019-04-05 13:10:29,589 : INFO : EPOCH 2 - PROGRESS: at 70.43% examples, 345296 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:30,634 : INFO : EPOCH 2 - PROGRESS: at 74.58% examples, 342315 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-05 13:10:31,726 : INFO : EPOCH 2 - PROGRESS: at 78.45% examples, 338011 words/s, in_qsize 6, out_qsize 5\n",
      "2019-04-05 13:10:32,772 : INFO : EPOCH 2 - PROGRESS: at 83.01% examples, 338029 words/s, in_qsize 3, out_qsize 4\n",
      "2019-04-05 13:10:33,786 : INFO : EPOCH 2 - PROGRESS: at 87.21% examples, 336862 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-05 13:10:34,815 : INFO : EPOCH 2 - PROGRESS: at 91.23% examples, 334946 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-05 13:10:35,876 : INFO : EPOCH 2 - PROGRESS: at 95.27% examples, 333155 words/s, in_qsize 4, out_qsize 3\n",
      "2019-04-05 13:10:36,750 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-05 13:10:36,765 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-05 13:10:36,781 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-05 13:10:36,781 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-05 13:10:36,781 : INFO : EPOCH - 2 : training on 10872154 raw words (7613901 effective words) took 22.7s, 335616 effective words/s\n",
      "2019-04-05 13:10:37,826 : INFO : EPOCH 3 - PROGRESS: at 4.53% examples, 332260 words/s, in_qsize 8, out_qsize 3\n",
      "2019-04-05 13:10:38,840 : INFO : EPOCH 3 - PROGRESS: at 9.40% examples, 350213 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:39,854 : INFO : EPOCH 3 - PROGRESS: at 14.33% examples, 353137 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:10:40,868 : INFO : EPOCH 3 - PROGRESS: at 19.20% examples, 355507 words/s, in_qsize 6, out_qsize 0\n",
      "2019-04-05 13:10:41,898 : INFO : EPOCH 3 - PROGRESS: at 23.78% examples, 354397 words/s, in_qsize 7, out_qsize 2\n",
      "2019-04-05 13:10:42,896 : INFO : EPOCH 3 - PROGRESS: at 27.80% examples, 346818 words/s, in_qsize 8, out_qsize 1\n",
      "2019-04-05 13:10:43,926 : INFO : EPOCH 3 - PROGRESS: at 31.74% examples, 337892 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:10:44,955 : INFO : EPOCH 3 - PROGRESS: at 35.92% examples, 332864 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:45,969 : INFO : EPOCH 3 - PROGRESS: at 40.83% examples, 336395 words/s, in_qsize 6, out_qsize 0\n",
      "2019-04-05 13:10:46,983 : INFO : EPOCH 3 - PROGRESS: at 45.84% examples, 339832 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:10:48,013 : INFO : EPOCH 3 - PROGRESS: at 49.73% examples, 335404 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-05 13:10:49,027 : INFO : EPOCH 3 - PROGRESS: at 54.00% examples, 334374 words/s, in_qsize 6, out_qsize 0\n",
      "2019-04-05 13:10:50,056 : INFO : EPOCH 3 - PROGRESS: at 58.00% examples, 331938 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:51,117 : INFO : EPOCH 3 - PROGRESS: at 61.45% examples, 325260 words/s, in_qsize 7, out_qsize 4\n",
      "2019-04-05 13:10:52,147 : INFO : EPOCH 3 - PROGRESS: at 65.09% examples, 321958 words/s, in_qsize 8, out_qsize 1\n",
      "2019-04-05 13:10:53,176 : INFO : EPOCH 3 - PROGRESS: at 67.69% examples, 314118 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-05 13:10:54,206 : INFO : EPOCH 3 - PROGRESS: at 71.53% examples, 312216 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:10:55,220 : INFO : EPOCH 3 - PROGRESS: at 74.85% examples, 308704 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:10:56,265 : INFO : EPOCH 3 - PROGRESS: at 78.97% examples, 308197 words/s, in_qsize 6, out_qsize 2\n",
      "2019-04-05 13:10:57,295 : INFO : EPOCH 3 - PROGRESS: at 84.08% examples, 311863 words/s, in_qsize 6, out_qsize 0\n",
      "2019-04-05 13:10:58,293 : INFO : EPOCH 3 - PROGRESS: at 89.02% examples, 315188 words/s, in_qsize 6, out_qsize 0\n",
      "2019-04-05 13:10:59,307 : INFO : EPOCH 3 - PROGRESS: at 93.32% examples, 315662 words/s, in_qsize 8, out_qsize 2\n",
      "2019-04-05 13:11:00,337 : INFO : EPOCH 3 - PROGRESS: at 97.30% examples, 314822 words/s, in_qsize 5, out_qsize 5\n",
      "2019-04-05 13:11:00,867 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-05 13:11:00,883 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-05 13:11:00,883 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-05 13:11:00,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-05 13:11:00,898 : INFO : EPOCH - 3 : training on 10872154 raw words (7615037 effective words) took 24.1s, 316024 effective words/s\n",
      "2019-04-05 13:11:01,959 : INFO : EPOCH 4 - PROGRESS: at 3.25% examples, 232651 words/s, in_qsize 6, out_qsize 0\n",
      "2019-04-05 13:11:02,989 : INFO : EPOCH 4 - PROGRESS: at 6.95% examples, 251230 words/s, in_qsize 5, out_qsize 0\n",
      "2019-04-05 13:11:03,987 : INFO : EPOCH 4 - PROGRESS: at 11.25% examples, 276252 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:05,001 : INFO : EPOCH 4 - PROGRESS: at 16.36% examples, 300833 words/s, in_qsize 6, out_qsize 0\n",
      "2019-04-05 13:11:06,000 : INFO : EPOCH 4 - PROGRESS: at 19.75% examples, 292167 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:07,014 : INFO : EPOCH 4 - PROGRESS: at 23.87% examples, 296675 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:11:08,012 : INFO : EPOCH 4 - PROGRESS: at 28.07% examples, 299875 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:09,042 : INFO : EPOCH 4 - PROGRESS: at 32.95% examples, 306741 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-05 13:11:10,071 : INFO : EPOCH 4 - PROGRESS: at 38.29% examples, 315670 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:11,116 : INFO : EPOCH 4 - PROGRESS: at 43.54% examples, 321819 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:11:12,115 : INFO : EPOCH 4 - PROGRESS: at 48.35% examples, 326117 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:11:13,129 : INFO : EPOCH 4 - PROGRESS: at 53.46% examples, 331349 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:14,127 : INFO : EPOCH 4 - PROGRESS: at 58.28% examples, 334003 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-05 13:11:15,141 : INFO : EPOCH 4 - PROGRESS: at 63.20% examples, 336569 words/s, in_qsize 8, out_qsize 1\n",
      "2019-04-05 13:11:16,155 : INFO : EPOCH 4 - PROGRESS: at 68.36% examples, 340219 words/s, in_qsize 5, out_qsize 0\n",
      "2019-04-05 13:11:17,169 : INFO : EPOCH 4 - PROGRESS: at 73.59% examples, 343373 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:18,168 : INFO : EPOCH 4 - PROGRESS: at 78.62% examples, 345710 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:19,182 : INFO : EPOCH 4 - PROGRESS: at 83.70% examples, 348021 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:20,242 : INFO : EPOCH 4 - PROGRESS: at 88.46% examples, 348024 words/s, in_qsize 8, out_qsize 4\n",
      "2019-04-05 13:11:21,272 : INFO : EPOCH 4 - PROGRESS: at 93.68% examples, 350057 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-05 13:11:22,286 : INFO : EPOCH 4 - PROGRESS: at 97.64% examples, 347848 words/s, in_qsize 8, out_qsize 1\n",
      "2019-04-05 13:11:22,770 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-05 13:11:22,785 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-05 13:11:22,801 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-05 13:11:22,816 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-05 13:11:22,816 : INFO : EPOCH - 4 : training on 10872154 raw words (7611965 effective words) took 21.9s, 347399 effective words/s\n",
      "2019-04-05 13:11:23,846 : INFO : EPOCH 5 - PROGRESS: at 3.99% examples, 298587 words/s, in_qsize 7, out_qsize 1\n",
      "2019-04-05 13:11:24,844 : INFO : EPOCH 5 - PROGRESS: at 8.58% examples, 323867 words/s, in_qsize 4, out_qsize 0\n",
      "2019-04-05 13:11:25,858 : INFO : EPOCH 5 - PROGRESS: at 13.55% examples, 337492 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:26,872 : INFO : EPOCH 5 - PROGRESS: at 18.82% examples, 351927 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:27,871 : INFO : EPOCH 5 - PROGRESS: at 23.60% examples, 355364 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:11:28,900 : INFO : EPOCH 5 - PROGRESS: at 28.73% examples, 360039 words/s, in_qsize 8, out_qsize 1\n",
      "2019-04-05 13:11:29,914 : INFO : EPOCH 5 - PROGRESS: at 34.14% examples, 364510 words/s, in_qsize 7, out_qsize 1\n",
      "2019-04-05 13:11:30,960 : INFO : EPOCH 5 - PROGRESS: at 38.38% examples, 356904 words/s, in_qsize 7, out_qsize 4\n",
      "2019-04-05 13:11:32,036 : INFO : EPOCH 5 - PROGRESS: at 43.18% examples, 354048 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-05 13:11:33,050 : INFO : EPOCH 5 - PROGRESS: at 48.08% examples, 356163 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:34,049 : INFO : EPOCH 5 - PROGRESS: at 52.66% examples, 355383 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:11:35,063 : INFO : EPOCH 5 - PROGRESS: at 57.21% examples, 354348 words/s, in_qsize 8, out_qsize 1\n",
      "2019-04-05 13:11:36,061 : INFO : EPOCH 5 - PROGRESS: at 62.57% examples, 358231 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:37,075 : INFO : EPOCH 5 - PROGRESS: at 67.49% examples, 359971 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:11:38,105 : INFO : EPOCH 5 - PROGRESS: at 71.80% examples, 357301 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:39,150 : INFO : EPOCH 5 - PROGRESS: at 76.15% examples, 354294 words/s, in_qsize 5, out_qsize 2\n",
      "2019-04-05 13:11:40,148 : INFO : EPOCH 5 - PROGRESS: at 79.95% examples, 350763 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-05 13:11:41,147 : INFO : EPOCH 5 - PROGRESS: at 84.25% examples, 349436 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:42,161 : INFO : EPOCH 5 - PROGRESS: at 88.39% examples, 347896 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-05 13:11:43,175 : INFO : EPOCH 5 - PROGRESS: at 91.68% examples, 342926 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:11:44,189 : INFO : EPOCH 5 - PROGRESS: at 96.18% examples, 342987 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-05 13:11:44,922 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-05 13:11:44,937 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-05 13:11:44,953 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-05 13:11:44,984 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-05 13:11:44,984 : INFO : EPOCH - 5 : training on 10872154 raw words (7613435 effective words) took 22.1s, 343787 effective words/s\n",
      "2019-04-05 13:11:44,984 : INFO : training on a 54360770 raw words (38067250 effective words) took 114.3s, 332928 effective words/s\n",
      "2019-04-05 13:11:44,984 : INFO : precomputing L2-norms of word weight vectors\n",
      "2019-04-05 13:11:45,249 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2019-04-05 13:11:45,249 : INFO : not storing attribute vectors_norm\n",
      "2019-04-05 13:11:45,249 : INFO : not storing attribute cum_table\n",
      "2019-04-05 13:11:45,889 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "print (\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, size = num_features, min_count = min_word_count,\n",
    "                          window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace = True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)\n",
    "#model.word2vec_model.wv.save_word2vec_format(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-05 13:11:47,043 : INFO : loading Word2VecKeyedVectors object from 300features_40minwords_10context\n",
      "2019-04-05 13:11:47,481 : INFO : loading wv recursively from 300features_40minwords_10context.wv.* with mmap=None\n",
      "2019-04-05 13:11:47,481 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-04-05 13:11:47,481 : INFO : loading vocabulary recursively from 300features_40minwords_10context.vocabulary.* with mmap=None\n",
      "2019-04-05 13:11:47,481 : INFO : loading trainables recursively from 300features_40minwords_10context.trainables.* with mmap=None\n",
      "2019-04-05 13:11:47,497 : INFO : setting ignored attribute cum_table to None\n",
      "2019-04-05 13:11:47,497 : INFO : loaded 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "# Load the model that we created \n",
    "model = KeyedVectors.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)      \n",
    "    return feature_vector  \n",
    "   \n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features) \n",
    "                for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/dALZL6ZuOV\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/daznQZR8Te\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/NXgtqSlchG\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/ltoXYPKWww\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/bN7be6njVT\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/3hqI0L6cwU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/nO5U2nLuGc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/YnGATgiK5F\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/W1WmvCXAvm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/iQF3M9X1NK\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/Xvg4LrPWD5\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/vSObneH81v\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/3nr1XjZaW6\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://t.co/f2NxFZ8VTz\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"labeled_data.csv\",encoding=\"latin-1\")\n",
    "\n",
    "clean_tweets = []\n",
    "for tweet in data[\"tweet\"]:\n",
    "    clean_tweets.append( tweet_to_wordlist( tweet, remove_stopwords=True ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "encodings_data = averaged_word_vectorizer(corpus=clean_tweets, model=model, num_features=num_features)\n",
    "\n",
    "X = pd.DataFrame(encodings_data)\n",
    "y = data['class'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=69, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   9.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   9.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   9.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   47.7s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('select', SelectFromModel(LogisticRegression(class_weight='balanced', penalty=\"l1\", C=0.01))),\n",
    "                 ('model', LogisticRegression(class_weight='balanced',penalty='l2'))])\n",
    "param_grid = [{}]\n",
    "grid_search = GridSearchCV(pipe, param_grid,cv=StratifiedKFold(n_splits=5, random_state=69).split(X_train, y_train), verbose=2)\n",
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.60      0.62      8186\n",
      "          1       0.75      0.70      0.72     14805\n",
      "          2       0.74      0.81      0.77     16957\n",
      "\n",
      "avg / total       0.72      0.72      0.72     39948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.5min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 3.9min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 20.4min finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('select', SelectFromModel(LogisticRegression(class_weight='balanced', penalty=\"l1\", C=0.01))),\n",
    "                 ('model', RandomForestClassifier(n_estimators=300, random_state=0))])\n",
    "param_grid = [{}]\n",
    "grid_search = GridSearchCV(pipe, param_grid,cv=StratifiedKFold(n_splits=5, random_state=69).split(X_train, y_train), verbose=2)\n",
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.61      0.71      8186\n",
      "          1       0.84      0.81      0.83     14805\n",
      "          2       0.78      0.91      0.84     16957\n",
      "\n",
      "avg / total       0.82      0.81      0.81     39948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   7.1s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   6.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   34.0s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('select', SelectFromModel(LogisticRegression(class_weight='balanced', penalty=\"l1\", C=0.01))),\n",
    "                 ('model', LinearSVC(C=0.05,random_state=0))])\n",
    "param_grid = [{}] \n",
    "grid_search = GridSearchCV(pipe, param_grid,cv=StratifiedKFold(n_splits=5, random_state=69).split(X_train, y_train), verbose=2)\n",
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.45      0.56      8186\n",
      "          1       0.72      0.71      0.72     14805\n",
      "          2       0.71      0.86      0.77     16957\n",
      "\n",
      "avg / total       0.72      0.72      0.71     39948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   6.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   29.9s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('select', SelectFromModel(LogisticRegression(class_weight='balanced', penalty=\"l1\", C=0.01))),\n",
    "                 ('model', ExtraTreeClassifier())])\n",
    "param_grid = [{}] \n",
    "grid_search = GridSearchCV(pipe, param_grid,cv=StratifiedKFold(n_splits=5, random_state=69).split(X_train, y_train), verbose=2)\n",
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.61      0.61      8186\n",
      "          1       0.73      0.77      0.75     14805\n",
      "          2       0.76      0.72      0.74     16957\n",
      "\n",
      "avg / total       0.72      0.72      0.72     39948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.7s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   5.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   29.9s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('select', SelectFromModel(LogisticRegression(class_weight='balanced', penalty=\"l1\", C=0.01))),\n",
    "                 ('model', BernoulliNB())])\n",
    "\n",
    "param_grid = [{}]\n",
    "grid_search = GridSearchCV(pipe, param_grid,cv=StratifiedKFold(n_splits=5, random_state=69).split(X_train, y_train), verbose=2)\n",
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.45      0.50      8186\n",
      "          1       0.66      0.68      0.67     14805\n",
      "          2       0.72      0.77      0.75     16957\n",
      "\n",
      "avg / total       0.67      0.67      0.67     39948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
